import gym
import numpy as np
import cv2
import time
import win32gui, win32ui, win32con
from collections import deque
import pytesseract
import platform
# ç¡®ä¿æ‰€æœ‰é…ç½®å¸¸é‡éƒ½å·²å¯¼å…¥ï¼Œè¿™é‡Œå‡è®¾ config.py å·²ç»å°±ç»ª
from config import *

# --- å¼ºåˆ¶è®¾ç½® Tesseract è·¯å¾„ ---
if platform.system() == 'Windows':
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH


class BVNEnv(gym.Env):
    def __init__(self):
        super(BVNEnv, self).__init__()
        self.hwnd = win32gui.FindWindow(None, GAME_TITLE)
        if not self.hwnd:
            raise Exception(f"æœªæ‰¾åˆ°çª—å£: {GAME_TITLE}")

        if win32gui.IsIconic(self.hwnd):
            raise Exception("çª—å£å·²æœ€å°åŒ–ï¼Œè¯·è¿˜åŸçª—å£ã€‚")

        self.frames = deque(maxlen=SEQUENCE_LENGTH)

    def _grab_screen_win32(self):
        left, top, right, bot = win32gui.GetClientRect(self.hwnd)
        w, h = right - left, bot - top
        if w == 0 or h == 0: return np.zeros((100, 100, 3), dtype=np.uint8)

        hwindc = win32gui.GetWindowDC(self.hwnd)
        srcdc = win32ui.CreateDCFromHandle(hwindc)
        memdc = srcdc.CreateCompatibleDC()
        bmp = win32ui.CreateBitmap()
        bmp.CreateCompatibleBitmap(srcdc, w, h)
        memdc.SelectObject(bmp)

        # ä¿®æ­£ BitBlt å‚æ•°ï¼šç¡®ä¿æ­£ç¡®æˆªå›¾ w x h åŒºåŸŸ
        memdc.BitBlt((0, 0), (w, h), srcdc, (0, 0), win32con.SRCCOPY)

        signedIntsArray = bmp.GetBitmapBits(True)
        img = np.frombuffer(signedIntsArray, dtype='uint8')
        img.shape = (h, w, 4)

        srcdc.DeleteDC()
        memdc.DeleteDC()
        win32gui.ReleaseDC(self.hwnd, hwindc)
        win32gui.DeleteObject(bmp.GetHandle())

        return cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)

    def _read_ocr_value(self, img, rect, max_val=None):
        """
        é€šç”¨ OCR è¯»å–æ•´æ•°æ•°å­— (ä»…ç”¨äº HP/Timeï¼Œä½¿ç”¨å•è‰² DIGIT_COLOR é˜ˆå€¼)ã€‚
        """
        x, y, w, h = rect
        # è¾¹ç•Œæ£€æŸ¥
        if y + h > img.shape[0] or x + w > img.shape[1] or w <= 0 or h <= 0:
            return 0, 0.0, (x, y, w, h)

        roi = img[y:y + h, x:x + w]
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

        # å•è‰²è¿‡æ»¤ï¼ˆç”¨äºç™½è‰²æ•°å­—ï¼‰
        mask = cv2.inRange(hsv, np.array(DIGIT_COLOR_LOWER), np.array(DIGIT_COLOR_UPPER))

        # åè½¬ï¼šå¾—åˆ°ç™½åº•é»‘å­—ï¼ˆTesseract åçˆ±æ ¼å¼ï¼‰
        final_img = cv2.bitwise_not(mask)

        # è¯†åˆ«æ•´æ•°
        config = '--psm 7 -c tessedit_char_whitelist=0123456789'
        try:
            text = pytesseract.image_to_string(final_img, config=config).strip()
            val = int(text) if text else 0
        except Exception as e:
            val = 0

        ratio = np.clip(val / max_val, 0.0, 1.0) if max_val else 0.0

        return val, ratio, (x, y, w, h)

    # ğŸ”¥ æ–°å¢/æ›¿æ¢ï¼šé€šè¿‡é¢œè‰²ç»Ÿè®¡è¯»å–æ€’æ°”/æ°”é‡ç­‰çº§ (0, 1, 2, æˆ– 3)
    def _read_gauge_level_by_color(self, raw_img, rect):
        """
        é€šè¿‡é¢œè‰²ç»Ÿè®¡è¯»å–æ€’æ°”/æ°”é‡ç­‰çº§ (1, 2, æˆ– 3)ã€‚
        ã€å·²æ·»åŠ è°ƒè¯•è¾“å‡ºã€‘ä»¥å¸®åŠ©æ ¡å‡† HSV é˜ˆå€¼ã€‚
        """
        x, y, w, h = rect
        if y + h > raw_img.shape[0] or x + w > raw_img.shape[1] or w <= 0 or h <= 0:
            return 0, (x, y, w, h)

        roi = raw_img[y:y + h, x:x + w]
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

        # --- DEBUG 1: æ‰“å° ROI çš„å¹³å‡ HSV å€¼ ---
        # è§‚å¯Ÿè¿™äº›å€¼ï¼Œç„¶åå»ä¿®æ”¹ config.py ä¸­çš„ H èŒƒå›´
        # h_mean, s_mean, v_mean = cv2.mean(hsv, mask=None)[:3]
        # print(f"--- RAGE ROI ({x},{y}) MEAN HSV: H={h_mean:.2f}, S={s_mean:.2f}, V={v_mean:.2f} ---")

        # å®šä¹‰é¢œè‰²èŒƒå›´å’Œå¯¹åº”çš„ç­‰çº§ (ä»æœ€é«˜ç­‰çº§ 3 å¼€å§‹æ£€æŸ¥)
        color_levels = [
            # 3çº§ (çº¢è‰²) - æ£€æŸ¥ä¸¤ä¸ª H èŒƒå›´
            ("3R_1", GAUGE_3_COLOR_LOWER_1, GAUGE_3_COLOR_UPPER_1, 3),
            ("3R_2", GAUGE_3_COLOR_LOWER_2, GAUGE_3_COLOR_UPPER_2, 3),

            # 2çº§ (æ©™è‰²)
            ("2O", GAUGE_2_COLOR_LOWER, GAUGE_2_COLOR_UPPER, 2),

            # 1çº§ (ç»¿è‰²)
            ("1G", GAUGE_1_COLOR_LOWER, GAUGE_1_COLOR_UPPER, 1),
        ]

        # éå†ï¼šä» 3 çº§æ°”å¼€å§‹ï¼Œå¦‚æœå‘ç°è¶³å¤Ÿå¤šçš„ç›®æ ‡é¢œè‰²åƒç´ ï¼Œåˆ™ç«‹å³è¿”å›è¯¥ç­‰çº§
        for name, lower, upper, level in color_levels:
            lower_np = np.array(lower)
            upper_np = np.array(upper)

            mask = cv2.inRange(hsv, lower_np, upper_np)
            color_count = cv2.countNonZero(mask)

            # --- DEBUG 2: æ‰“å°æ¯ä¸ªç­‰çº§çš„åƒç´ è®¡æ•° ---
            # print(f"  Level {name} Count: {color_count} (Min={GAUGE_MIN_PIXEL_COUNT})")

            # å¦‚æœæ‰¾åˆ°è¶³å¤Ÿå¤šçš„åƒç´ ï¼ˆé«˜äºé˜ˆå€¼ï¼‰ï¼Œåˆ™ç«‹å³è®¤ä¸ºè¿™æ˜¯å½“å‰ç­‰çº§
            if color_count >= GAUGE_MIN_PIXEL_COUNT:
                # print(f"*** DETECTED LEVEL {level} by color {name} ***")
                return level, (x, y, w, h)

        # å¦‚æœä»¥ä¸Šæ‰€æœ‰ç­‰çº§ (1, 2, 3) éƒ½ä¸æ»¡è¶³æœ€å°åƒç´ é˜ˆå€¼ï¼Œè¿”å›é»˜è®¤å€¼ 0
        return 0, (x, y, w, h)

    def _read_ready_state(self, raw_img, rect):
        """é€šè¿‡é¢œè‰²ç»Ÿè®¡è¯»å– Ready çŠ¶æ€ (å¸ƒå°”å€¼)"""
        x, y, w, h = rect
        if y + h > raw_img.shape[0] or x + w > raw_img.shape[1] or w <= 0 or h <= 0:
            return False, (x, y, w, h)

        roi = raw_img[y:y + h, x:x + w]
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        total_pixels = w * h

        # ä½¿ç”¨ READY_COLOR é˜ˆå€¼åˆ›å»ºæ©ç 
        lower_np = np.array(READY_COLOR_LOWER)
        upper_np = np.array(READY_COLOR_UPPER)
        mask = cv2.inRange(hsv, lower_np, upper_np)

        # ç»Ÿè®¡åŒ¹é…ç›®æ ‡é¢œè‰²çš„åƒç´ æ•°
        color_count = cv2.countNonZero(mask)

        # å¦‚æœç›®æ ‡é¢œè‰²åƒç´ å æ¯”è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™è®¤ä¸º Ready çŠ¶æ€ä¸º True
        is_ready = (color_count / total_pixels) >= READY_COLOR_MIN_RATIO

        return is_ready, (x, y, w, h)

    def _find_character_box(self, img, lower, upper):
        """åˆ©ç”¨æ¸¸æˆè‡ªå¸¦çš„äººç‰©æ¡†é¢œè‰²å®šä½äººç‰©"""
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv, lower, upper)

        # å½¢æ€å­¦å¤„ç†ï¼Œå»é™¤å™ªå£°
        mask = cv2.dilate(mask, None, iterations=4)
        mask = cv2.erode(mask, None, iterations=2)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if contours:
            c = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(c)

            # åŸºç¡€è¿‡æ»¤ï¼šæ’é™¤æå°çš„å™ªå£°
            if w < 10 or h < 10:
                return (0, 0), (0, 0, 0, 0)

            center = (x + w // 2, y + h // 2)
            return center, (x, y, w, h)

        return (0, 0), (0, 0, 0, 0)

    # å…³é”®ä¿®æ”¹ï¼šæ›¿æ¢æ€’æ°”è¯»å–é€»è¾‘
    def _process_frame(self, raw_img):
        # 1. è¯»å–è¡€é‡ã€æ—¶é—´å’Œæ€’æ°”

        # HP/Time ä½¿ç”¨é»˜è®¤å•è‰² OCR
        p1_val, p1_ratio, p1_rect_ocr = self._read_ocr_value(raw_img, OCR_P1_HP_RECT, max_val=MAX_HP)
        p2_val, p2_ratio, p2_rect_ocr = self._read_ocr_value(raw_img, OCR_P2_HP_RECT, max_val=MAX_HP)
        time_val, _, time_rect_ocr = self._read_ocr_value(raw_img, OCR_TIME_RECT)

        #  æ€’æ°”å€¼ï¼šä½¿ç”¨æ–°çš„é¢œè‰²ç»Ÿè®¡è¯†åˆ«å‡½æ•°
        p1_rage_val, p1_rage_rect_ocr = self._read_gauge_level_by_color(raw_img, OCR_P1_RAGE_RECT)
        p2_rage_val, p2_rage_rect_ocr = self._read_gauge_level_by_color(raw_img, OCR_P2_RAGE_RECT)

        #  Ready çŠ¶æ€è¯»å–
        p1_ready_state, p1_ready_rect = self._read_ready_state(raw_img, OCR_P1_READY_RECT)
        p2_ready_state, p2_ready_rect = self._read_ready_state(raw_img, OCR_P2_READY_RECT)

        # 2. äººç‰©å®šä½ (ä¿æŒä¸å˜)
        p1_center, p1_box_rect = self._find_character_box(raw_img, np.array(P1_BOX_LOWER), np.array(P1_BOX_UPPER))
        p2_center, p2_box_rect = self._find_character_box(raw_img, np.array(P2_BOX_LOWER), np.array(P2_BOX_UPPER))

        # 3. å›¾åƒé¢„å¤„ç† (ä¿æŒä¸å˜)
        gray = cv2.cvtColor(raw_img, cv2.COLOR_BGR2GRAY)
        global_view = cv2.resize(gray, (FULL_IMG_SIZE, FULL_IMG_SIZE))

        def crop_local(center):
            cx, cy = center
            x1, y1 = max(0, cx - 50), max(0, cy - 50)
            x2, y2 = min(raw_img.shape[1], cx + 50), min(raw_img.shape[0], cy + 50)
            crop = gray[y1:y2, x1:x2]
            if crop.shape[0] < 10 or crop.shape[1] < 10:
                return np.zeros((LOCAL_IMG_SIZE, LOCAL_IMG_SIZE), dtype=np.uint8)
            return cv2.resize(crop, (LOCAL_IMG_SIZE, LOCAL_IMG_SIZE))

        local_p1 = crop_local(p1_center)
        local_p2 = crop_local(p2_center)

        # å‘é‡æ•°æ®ï¼š5ä¸ªåæ ‡/è·ç¦»
        vec = np.array([p1_center[0], p1_center[1], p2_center[0], p2_center[1],
                        np.linalg.norm(np.array(p1_center) - np.array(p2_center))], dtype=np.float32)

        # 4. å¯è§†åŒ–ç»˜åˆ¶ (ä¿æŒä¸å˜)
        vis_img = raw_img.copy()

        # [P1 HP] (ç»¿è‰²)
        cv2.rectangle(vis_img, (p1_rect_ocr[0], p1_rect_ocr[1]),
                      (p1_rect_ocr[0] + p1_rect_ocr[2], p1_rect_ocr[1] + p1_rect_ocr[3]), (0, 255, 0), 2)
        cv2.putText(vis_img, f"P1 HP: {p1_val}", (p1_rect_ocr[0], p1_rect_ocr[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        # [P2 HP] (çº¢è‰²)
        cv2.rectangle(vis_img, (p2_rect_ocr[0], p2_rect_ocr[1]),
                      (p2_rect_ocr[0] + p2_rect_ocr[2], p2_rect_ocr[1] + p2_rect_ocr[3]), (0, 0, 255), 2)
        cv2.putText(vis_img, f"P2 HP: {p2_val}", (p2_rect_ocr[0], p2_rect_ocr[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        # [Time] (é’è‰²)
        cv2.rectangle(vis_img, (time_rect_ocr[0], time_rect_ocr[1]),
                      (time_rect_ocr[0] + time_rect_ocr[2], time_rect_ocr[1] + time_rect_ocr[3]), (255, 255, 0), 2)
        cv2.putText(vis_img, f"Time: {time_val}", (time_rect_ocr[0], time_rect_ocr[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)

        # [P1 Rage] (ç´«è‰²)
        cv2.rectangle(vis_img, (p1_rage_rect_ocr[0], p1_rage_rect_ocr[1]),
                      (p1_rage_rect_ocr[0] + p1_rage_rect_ocr[2], p1_rage_rect_ocr[1] + p1_rage_rect_ocr[3]),
                      (128, 0, 128), 2)
        cv2.putText(vis_img, f"R1: {p1_rage_val}", (p1_rage_rect_ocr[0], p1_rage_rect_ocr[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (128, 0, 128), 2)

        # [P2 Rage] (æ©™è‰²)
        cv2.rectangle(vis_img, (p2_rage_rect_ocr[0], p2_rage_rect_ocr[1]),
                      (p2_rage_rect_ocr[0] + p2_rage_rect_ocr[2], p2_rage_rect_ocr[1] + p2_rage_rect_ocr[3]),
                      (0, 165, 255), 2)
        cv2.putText(vis_img, f"R2: {p2_rage_val}", (p2_rage_rect_ocr[0], p2_rage_rect_ocr[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 165, 255), 2)

        # [P1 Ready] (è“è‰²)
        cv2.rectangle(vis_img, (p1_ready_rect[0], p1_ready_rect[1]),
                      (p1_ready_rect[0] + p1_ready_rect[2], p1_ready_rect[1] + p1_ready_rect[3]), (255, 0, 0), 2)
        cv2.putText(vis_img, f"P1 Rdy: {p1_ready_state}", (p1_ready_rect[0], p1_ready_rect[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

        # [P2 Ready] (æµ…è“è‰²)
        cv2.rectangle(vis_img, (p2_ready_rect[0], p2_ready_rect[1]),
                      (p2_ready_rect[0] + p2_ready_rect[2], p2_ready_rect[1] + p2_ready_rect[3]), (255, 255, 0), 2)
        cv2.putText(vis_img, f"P2 Rdy: {p2_ready_state}", (p2_ready_rect[0], p2_ready_rect[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)

        # [P1/P2 äººç‰©è¿½è¸ªæ¡†]
        cv2.rectangle(vis_img, (p1_box_rect[0], p1_box_rect[1]),
                      (p1_box_rect[0] + p1_box_rect[2], p1_box_rect[1] + p1_box_rect[3]), (255, 0, 0), 2)
        cv2.rectangle(vis_img, (p2_box_rect[0], p2_box_rect[1]),
                      (p2_box_rect[0] + p2_box_rect[2], p2_box_rect[1] + p2_box_rect[3]), (0, 255, 255), 2)

        return {
            "global": global_view, "local_p1": local_p1, "local_p2": local_p2,
            "vec": vec,
            "hp_vals": (p1_val, p2_val),
            "hp_ratios": (p1_ratio, p2_ratio),
            "time": time_val,
            "rage_vals": (p1_rage_val, p2_rage_val),
            "ready_states": (p1_ready_state, p2_ready_state),
            "vis_img": vis_img
        }

    def reset(self):
        self.frames.clear()
        img = self._grab_screen_win32()
        data = self._process_frame(img)
        for _ in range(SEQUENCE_LENGTH):
            self.frames.append(data)
        return list(self.frames)

    def step(self, action):
        from game_actions import execute_action
        execute_action(action)

        img = self._grab_screen_win32()
        new_data = self._process_frame(img)
        self.frames.append(new_data)

        r_curr = new_data['hp_ratios'][0] - new_data['hp_ratios'][1]
        r_prev = self.frames[-2]['hp_ratios'][0] - self.frames[-2]['hp_ratios'][1]
        reward = (r_curr - r_prev) * 10

        done = new_data['hp_ratios'][0] <= 0 or new_data['hp_ratios'][1] <= 0 or new_data['time'] <= 0

        cv2.imshow("AI Vision Debug", new_data['vis_img'])
        cv2.waitKey(1)

        return list(self.frames), reward, done, {}